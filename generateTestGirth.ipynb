{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35b0e51f",
   "metadata": {},
   "source": [
    "# Test Generator (Girth)\n",
    "\n",
    "Read in the candidates and item data and generate a randomised test from them using the\n",
    "[Girth](https://eribean.github.io/girth/) package\n",
    "\n",
    "We assume that the 1PL model is used.\n",
    "\n",
    "$$\n",
    "Pr(X=1) = \\frac{exp(\\theta-b)}{1 + exp(\\theta-b)}\n",
    "$$\n",
    "\n",
    "The benefit of using the Girth library is that is it in addition to generating synthetic test data it can also be used to estimate the IRT parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d49bdfd",
   "metadata": {},
   "source": [
    "## Data Ingest\n",
    "\n",
    "There are two files in the `data` folder that we need: `items.csv` and `candidates.csv`. If you want to generate a randomised set of candidates, then run the `generateCandidates` notebook first. Note: this will overwrite the `candidates.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1295f8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "from typing import List, Tuple\n",
    "from csv import reader\n",
    "import pandas as pd\n",
    "from girth.synthetic import create_synthetic_irt_dichotomous, create_synthetic_irt_polytomous\n",
    "from girth import onepl_mml\n",
    "\n",
    "TEST_DICHOTOMOUS = 1\n",
    "TEST_SCALAR = 2\n",
    "\n",
    "CANDIDATE_ID = 0\n",
    "CANDIDATE_FNAME = 1\n",
    "CANDIDATE_SNAME = 2\n",
    "CANDIDATE_THETA = 3\n",
    "\n",
    "ITEM_ID = 0\n",
    "ITEM_A = 1\n",
    "ITEM_B = 2\n",
    "ITEM_K = 3\n",
    "\n",
    "\n",
    "def getDataAsList(datafile: str) -> List[Tuple]:\n",
    "    \"\"\"Turn a CSV datafile into a list of tuples\n",
    "\n",
    "    :param datafile: the CSV file to load data from\n",
    "    :return: a list of rows (tuples)\n",
    "    \"\"\"\n",
    "    with open(datafile, 'r', encoding='utf-8-sig') as fs:\n",
    "        csv_reader = reader(fs)\n",
    "        row_list = list(map(tuple, csv_reader))\n",
    "        return row_list[1:]    # ignore the header row\n",
    "    \n",
    "\n",
    "# convert the raw data into a simple duple of ( systemname, givenName, familyName, theta )\n",
    "def getCandidates() -> List[Tuple]:\n",
    "    candidates = getDataAsList('data/candidates.csv')\n",
    "    new_list = [(c[0], c[1], c[2], float(c[3])) for c in candidates]\n",
    "    return new_list\n",
    "    \n",
    "\n",
    "# convert the raw data into a simple triple of ( uiid, a, b )\n",
    "def getItems() -> List[Tuple]:\n",
    "    items = getDataAsList('data/items.csv')\n",
    "    new_list = [(i[0], float(i[1]), float(i[2]), int(i[5])) for i in items]\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e66197",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = getItems()\n",
    "# split the items into two sets: dichotomous and scalar items\n",
    "dichotomous_items = [i for i in items if i[ITEM_K] == 1]\n",
    "scalar_items = [i for i in items if i[ITEM_K] > 1]\n",
    "max_level = max([i[ITEM_K] for i in scalar_items])\n",
    "\n",
    "candidates = getCandidates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6a8af1",
   "metadata": {},
   "source": [
    "## Test Generation\n",
    "We use the `create_synthetic_irt_dichotomous()` and `create_synthetic_irt_polytomous()` functions from Girth to create the random test data. The `generateTest()` function reads data into the the numpy arrays that Girth requires, and then generates a randomised test before converting it into a pandas data frame for display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792757a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertTupleListToArray(tl: List[Tuple], arity: int):\n",
    "    l = [i[arity] for i in tl]\n",
    "    return np.array(l)\n",
    "\n",
    "\n",
    "def generateTest(itemList: List[Tuple], candidateList: List[Tuple], \n",
    "                 testType: int = TEST_DICHOTOMOUS, seed: int = None):\n",
    "    discrimination = convertTupleListToArray(itemList, ITEM_A)\n",
    "    theta = convertTupleListToArray(candidateList, CANDIDATE_THETA)\n",
    "    if testType == TEST_SCALAR:\n",
    "        # difficulty must be a [2D array (items x n_levels-1)] of difficulty parameters\n",
    "        difficulty = np.random.randn(len(itemList), max_level-1)\n",
    "        difficulty = np.sort(difficulty, 1)       \n",
    "        t = create_synthetic_irt_polytomous(difficulty, discrimination, theta, seed=seed)\n",
    "    else:\n",
    "        difficulty = convertTupleListToArray(itemList, ITEM_B)\n",
    "        t = create_synthetic_irt_dichotomous(difficulty, discrimination, theta, seed=seed)\n",
    "    return t\n",
    "\n",
    "\n",
    "def generateScalarTest(itemList: List[Tuple], candidateList: List[Tuple], seed: int = None):\n",
    "    synthetic_tests = []\n",
    "    for i in itemList:\n",
    "        t = generateTest(i, candidateList, TEST_SCALAR)\n",
    "        synthetic_tests.append[t]\n",
    "    \n",
    "\n",
    "def convertTestToDataframe(test, itemList: List[Tuple], candidateList: List[Tuple]):\n",
    "    header = []\n",
    "    for i in items:\n",
    "        header.append(i[0])\n",
    "    rownames = []\n",
    "    for i in candidates:\n",
    "        rownames.append(i[0])\n",
    "    df = pd.DataFrame(test.T, index=rownames, columns=header)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66dd156",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_test1 = generateTest(dichotomous_items, candidates, TEST_DICHOTOMOUS)\n",
    "synthetic_test2 = generateScalarTest(scalar_items, candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed6e8d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/p1/th5hdwpd5t7f883yg5zr6xp00000gp/T/ipykernel_26342/290645100.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msynthetic_test1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerateTest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdichotomous_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTEST_DICHOTOMOUS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msynthetic_test2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerateScalarTest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscalar_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/p1/th5hdwpd5t7f883yg5zr6xp00000gp/T/ipykernel_26342/3087413671.py\u001b[0m in \u001b[0;36mgenerateScalarTest\u001b[0;34m(itemList, candidateList, seed)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0msynthetic_tests\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitemList\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerateTest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidateList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTEST_SCALAR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0msynthetic_tests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/p1/th5hdwpd5t7f883yg5zr6xp00000gp/T/ipykernel_26342/3087413671.py\u001b[0m in \u001b[0;36mgenerateTest\u001b[0;34m(itemList, candidateList, testType, seed)\u001b[0m\n\u001b[1;32m      6\u001b[0m def generateTest(itemList: List[Tuple], candidateList: List[Tuple], \n\u001b[1;32m      7\u001b[0m                  testType: int = TEST_DICHOTOMOUS, seed: int = None):\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdiscrimination\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvertTupleListToArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitemList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mITEM_A\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvertTupleListToArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidateList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANDIDATE_THETA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtestType\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTEST_SCALAR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/p1/th5hdwpd5t7f883yg5zr6xp00000gp/T/ipykernel_26342/3087413671.py\u001b[0m in \u001b[0;36mconvertTupleListToArray\u001b[0;34m(tl, arity)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconvertTupleListToArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtl\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marity\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marity\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/p1/th5hdwpd5t7f883yg5zr6xp00000gp/T/ipykernel_26342/3087413671.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconvertTupleListToArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtl\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marity\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marity\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "items = dichotomous_items + scalar_items\n",
    "testDf = convertTestToDataframe(synthetic_test, items, candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9731b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = dichotomous_items + scalar_items\n",
    "testDf = convertTestToDataframe(synthetic_test, items, candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9731b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(testDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77f1227",
   "metadata": {},
   "source": [
    "### GenerateRandomTests function\n",
    "We also include a `GenerateRandomTests()` function that is the same as the one in the `generateTest.ipynb` notebook. You can then call the `GenerateRandomTests()` function as many times as you want to re-generate a test. It will generate different results every time (unless you pass in an integer seed value).\n",
    "\n",
    "Add items and candidates to the data files to generate larger tests.\n",
    "\n",
    "When you are happy with the results you can write out to a results CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e36347",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateRandomTests(seed: int = None):\n",
    "    synthetic_test = generateTest(items, candidates, seed)\n",
    "    testDf = convertTestToDataframe(synthetic_test, items, candidates)\n",
    "    return testDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6a4c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = GenerateRandomTests(89)\n",
    "\n",
    "(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbabc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/results.csv', index=True, index_label='systemname')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1279b9",
   "metadata": {},
   "source": [
    "### Solving using Standard Estimation\n",
    "You can use either maximum marginal likelihood (MML) or joint maximum likelihood (JML) estimation methods with the Girth library. Here we use MML estimation for the 1PL model (`onepl_mml`) to separately estimate the item parameters (`a` is the discrimination parameter and `bs` is an array of item difficulties) using univariate optimization methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d709409",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates = onepl_mml(synthetic_test)\n",
    "\n",
    "a = estimates['Discrimination']\n",
    "bs = estimates['Difficulty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f5cb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ede4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7adf3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
