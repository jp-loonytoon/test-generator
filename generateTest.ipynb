{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9a97d12",
   "metadata": {},
   "source": [
    "# Test Generator\n",
    "\n",
    "Read in the candidates and item data and generate a randomised test from them.\n",
    "\n",
    "We assume that the 1PL model is used.\n",
    "\n",
    "$$\n",
    "Pr(X=1) = \\frac{exp(\\theta-b)}{1 + exp(\\theta-b)}\n",
    "$$\n",
    "\n",
    "This test generator can generate tests with a mix of dichotomous and polytomous (scalar) items. The items are loaded from the file `data/items.csv` which looks like this:\n",
    "\n",
    "```\n",
    "UIID,a,b,se,rating,k\n",
    "A1L#01_7616,1.0,-6.59,0.0,A1,1\n",
    "A1L#02_20679,1.0,-5.36,0.0,A1,1\n",
    "A1L#03_5480,1.0,-4.64,0.0,A1,1\n",
    "A2L#04_5483,1.0,-4.2,0.0,A2,1\n",
    "```\n",
    "\n",
    "Here, the first two items: `A1L#01_7616` and `A1L#02_20679` are dichotomous (ie. `k = 1`), in other words they can take values '0' (incorrect) or '1' (correct); they have difficulty parameters `b` of -6.59 and -5.36 respectively. Difficulty thresholds used for any polytomous items are hardcoded in the `POLY_THRESHOLDS` list (see below) - they should really be different for each item."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83a810e",
   "metadata": {},
   "source": [
    "## Data Ingest\n",
    "\n",
    "There are two files in the `data` folder that we need: `items.csv` and `candidates.csv`. From these we generate a randomised test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a94c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "from typing import List, Tuple\n",
    "from csv import reader\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "# these are the threshold params (deltas) used for the scalar items\n",
    "# in a proper item bank, each item would have its own set of thresholds\n",
    "POLY_THRESHOLDS = [\n",
    "    {'1': -5.39, '2': 3.90}, # k = 2\n",
    "    {'1': -1.8, '2': -0.2, '3': 1.2}, # k = 3\n",
    "    {'1': -2.0, '2': -0.5, '3': 0.4, '4': 1.4}, # k = 4\n",
    "    {'1': -2.25, '2': -1.0, '3': 0.0, '4': 1.0, '5': 2.04}, # k = 5\n",
    "    {'1': -2.5, '2': -1.25, '3': -0.5, '4': 0.5, '5': 1.25, '6': 2.5}  # k = 6\n",
    "]\n",
    "\n",
    "COHORTS = ['Lo', 'Hi']\n",
    "\n",
    "def getDataAsList(datafile: str) -> List[Tuple]:\n",
    "    \"\"\"Turn a CSV datafile into a list of tuples\n",
    "\n",
    "    :param datafile: the CSV file to load data from\n",
    "    :return: a list of rows (tuples)\n",
    "    \"\"\"\n",
    "    with open(datafile, 'r', encoding='utf-8-sig') as fs:\n",
    "        csv_reader = reader(fs)\n",
    "        row_list = list(map(tuple, csv_reader))\n",
    "        return row_list[1:]    # ignore the header row\n",
    "    \n",
    "\n",
    "# convert the raw data from the candidates.csv file into\n",
    "# a simple quadruple of ( systemname, givenName, familyName, theta )\n",
    "def getCandidates() -> List[Tuple]:\n",
    "    candidates = getDataAsList('data/candidates.csv')\n",
    "    new_list = [(c[0], c[1], c[2], float(c[3])) for c in candidates]\n",
    "    return new_list\n",
    "    \n",
    "\n",
    "# convert the raw data from the items.csv file into\n",
    "# a simple triple of ( uiid, a, b )\n",
    "def getItems() -> List[Tuple]:\n",
    "    items = getDataAsList('data/items.csv')\n",
    "    new_list = [(i[0], float(i[1]), float(i[2]), int(i[5])) for i in items]\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f046ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = getItems()\n",
    "candidates = getCandidates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74ee5c5-643e-4ae2-b859-034c4c82dac7",
   "metadata": {},
   "source": [
    "## Item Response Generation\n",
    "\n",
    "The `getItemResponse()` function is used to generate a randomised response: correct (1) or incorrect (0) for a given candidate taking an item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5905a1e-2d3a-45a7-8bc6-ffbf374d4121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getItemResponse(b: float, theta: float, seed: int = None) -> str:\n",
    "    \"\"\"Gets a randomised dichotomous item response for a given candidate\n",
    "    according to the 1PL model:\n",
    "\n",
    "    P(X=1) = e^(theta-b) / 1 + e^(theta-b)\n",
    "\n",
    "    :param b: the difficulty parameter for the item\n",
    "    :param theta: the latent ability of the candidate\n",
    "    :return: '0' = incorrect, '1' = correct\n",
    "    \"\"\"\n",
    "    if seed is None:\n",
    "        rng = np.random.default_rng()\n",
    "    else:\n",
    "        rng = np.random.default_rng(seed)\n",
    "    rv = rng.random()\n",
    "\n",
    "    p1 = np.exp(theta - b) / (1 + np.exp(theta - b))\n",
    "    p0 = 1 - p1\n",
    "\n",
    "    assert p0 <= 1.0\n",
    "    assert p1 <= 1.0\n",
    "\n",
    "    rLookup = {\n",
    "        '0': [0.00, p0],\n",
    "        '1': [p0, 1.00]\n",
    "    }\n",
    "    r = {k: v for (k, v) in rLookup.items() if v[0] <= rv <= v[1]}\n",
    "    rKey = list(r.keys())\n",
    "\n",
    "    assert rKey[0] == '1' or rKey[0] == '0'\n",
    "\n",
    "    return rKey[0]\n",
    "\n",
    "\n",
    "def getScalarResponse(b: float, theta: float, k: int = 1, seed: int = None) -> str:\n",
    "    \"\"\"Gets a randomised polytomous item response for a given candidate\n",
    "    according to the 1PL model; uses the partial credit model (PCM) approach.\n",
    "    It uses the thresholds from POLY_THRESHOLDS to calculate what the difficulties\n",
    "    should be for each level.\n",
    "\n",
    "    :param b: the difficulty parameter for the item\n",
    "    :param theta: the latent ability of the candidate\n",
    "    :param k: the number of levels for the item (1 = dichotomous, 2+ = polytomous)\n",
    "    :param maxValue: the maximum possible value of the scalar response\n",
    "    :return: '0' = incorrect, '1' = correct\n",
    "    \"\"\"\n",
    "    assert k > 0\n",
    "    \n",
    "    response = 0\n",
    "    \n",
    "    if k == 1:\n",
    "        response = getItemResponse(b, theta, seed)\n",
    "    else:        \n",
    "        if seed is None:\n",
    "            rng = np.random.default_rng()\n",
    "        else:\n",
    "            rng = np.random.default_rng(seed)\n",
    "        rv = rng.random()\n",
    "        \n",
    "        rLookup = {}\n",
    "        rThresholds = POLY_THRESHOLDS[k-2]\n",
    "        rLookup['0'] = [0.00, rThresholds['1']]\n",
    "        p1 = p0 = 0.00\n",
    "        \n",
    "        for t in range(k+1):\n",
    "            p0 = p1\n",
    "            if t == k:\n",
    "                p1 = 1.0\n",
    "            else:\n",
    "                b = rThresholds[str(t+1)]\n",
    "                p1 = 1 - (np.exp(theta - b) / (1 + np.exp(theta - b)))\n",
    "            rLookup[str(t)] = [p0, p1]\n",
    "\n",
    "        r = {k: v for (k, v) in rLookup.items() if v[0] <= rv <= v[1]}\n",
    "        rKey = list(r.keys())    \n",
    "        response = rKey[0]\n",
    "        \n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7f2e1a-da1b-4983-8700-748ca64c2368",
   "metadata": {},
   "source": [
    "We iterate through the data and genereate item responses for each candidate. Each candidate takes a test comprising each item; with a simulated response being generated for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd9a993-f833-40b4-b84f-494fcf881ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateRandomTests(seed: int = None):\n",
    "    test_responses = [] # a list of lists\n",
    "\n",
    "    # generate a header row for the results\n",
    "    header = []\n",
    "    header.append('systemname')\n",
    "    for i in items:\n",
    "        header.append(i[0])\n",
    "\n",
    "    # now create the simulated test responses\n",
    "    for c in candidates:\n",
    "        test = []\n",
    "        test.append(c[0])\n",
    "\n",
    "        # choose a cohort for this candidate ('Lo', or 'Hi')\n",
    "        r = np.random.binomial(n=1, p=0.5)\n",
    "        candidateCohort = COHORTS[r]\n",
    "\n",
    "        for i in items:\n",
    "            uiid = i[0]\n",
    "            cohortMatch = re.search(\"Lo|Hi\", uiid)\n",
    "            if cohortMatch is not None:\n",
    "                itemCohort = cohortMatch.group()\n",
    "            else:\n",
    "                itemCohort = None\n",
    "            if (itemCohort is None) or (candidateCohort == itemCohort):\n",
    "                if i[3] > 2:\n",
    "                    # proivde a polytomous response\n",
    "                    r = int(getScalarResponse(i[2], c[3], i[3], seed))\n",
    "                else:\n",
    "                    # provide a dichomtomous response\n",
    "                    r = int(getItemResponse(i[2], c[3], seed))\n",
    "            else:\n",
    "                r = ''\n",
    "            \n",
    "            test.append(r)\n",
    "        test_responses.append(test)\n",
    "\n",
    "    df = pd.DataFrame(test_responses, columns=header)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a4a151-bea2-4fdf-9b1a-3cdcc0c425ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = GenerateRandomTests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66f9c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f783d0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de35549a",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "You can call the `GenerateRandomTests()` function as many times as you want to re-generate a test. It will generate different results every time (unless you pass in an integer seed value).\n",
    "\n",
    "Add items and candidates to the data files to generate larger tests.\n",
    "\n",
    "When you are happy with the results you can write out to a results CSV file like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8d38d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8eebb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
